{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Guide\n",
    "\n",
    "1. **[Import packages](#import_packages)**\n",
    "2. **[Preprocessing](#Preprocessing)**\n",
    "    1. **[Null Values Treatment](#null_values)**\n",
    "    2. **[Upper Lower Capping](#capping)**\n",
    "\n",
    "3. **[EDA](#EDA)**\n",
    "4. **[Model Building](#Model_Building)**\n",
    "5. **[Model Evaluation](#Model_Evaluation)**\n",
    "6. **[Conclusion](#Conclusion)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='import_packages'></a>\n",
    "## Data Loading And Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"BankCreditCard.csv\" , index_col=None, sep=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Preprocessing'></a>\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking For NAs <a id='null_values'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking For NAs Variables Having NA's\n",
    "\n",
    "drop_columns = []\n",
    "\n",
    "def get_na(data): \n",
    "    null_vars = data.isnull().sum()\n",
    "    null_vars = null_vars[null_vars > 0]\n",
    "    if(len(null_vars) > 0):\n",
    "        null_vars.sort_values(inplace=True)\n",
    "        null_vars.plot.bar(figsize=(15,4))\n",
    "    else:\n",
    "        print(\"No column have NA values\")\n",
    "get_na(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Variables those having significant NA Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute Values for NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(method=None, axis= 1, inplace=True)\n",
    "method='ffill'\n",
    "method='backfill'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting x(Independant) and y (Dependant Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.y\n",
    "x = data.drop(y, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical and Numerical Variables Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_categorical = x.select_type('O')\n",
    "data_numeric = x.drop(data_categorical, axis = 1, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='capping'></a>\n",
    "## Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper Caping and Lower Caping for numerical Attribute\n",
    "\n",
    "def set_caping(column, capping):\n",
    "    mean = column.mean() # Mean of the column\n",
    "    std = column.std() # Standard Deviation of the column\n",
    "    \n",
    "    UCL = mean + 3 * std\n",
    "    LCL = mean - 3 * std\n",
    "    if caping == \"both\":\n",
    "        data[column > UCL] = UCL\n",
    "        data[column < LCL] = LCL\n",
    "    elif caping == \"upper\":\n",
    "        data[column > UCL] = UCL\n",
    "    elif caping == \"lower\":\n",
    "        data[column > LCL] = LCL\n",
    "    else:\n",
    "        print(\"Please enter proper value of capping parameter. \\n Possible values:\\tboth\\tupper\\tlower\")\n",
    "\n",
    "# set_caping(data[\"age\"], capping = \"both\")\n",
    "# data.boxplot(column =\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "x_scaled = pd.DataFrame(scaler.transform(x), columns = df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data,pd.get_dummies(cat_data, drop_first=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='EDA'></a>\n",
    "## EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Plot For Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Columns those have strong Correlation for avoid multicoliniearity Issue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Price\n",
    "sale_price = original_data.SalePrice\n",
    "# With Square Root Transformation\n",
    "sqrt_price = np.sqrt(original_data.SalePrice)\n",
    "# With Square Log Transformation\n",
    "log_price = np.log(original_data.SalePrice)\n",
    "\n",
    "# Compare all Possibale Ways to get proper Transformation\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "prices = pd.DataFrame({\"Sale Price\":sale_price,\"Log Sale Price \":log_price, \"SQRT Price\":sqrt_price })\n",
    "prices.hist()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Feature_Engineering'></a>\n",
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Model_Building'></a>\n",
    "## Model Building Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devide Dataset into Train and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state=0)\n",
    "\n",
    "print(\"\\nx_train \",x_train.shape,\"\\nx_test \",x_test.shape, \"\\ny_train \",y_train.shape , \"\\ny_test \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression().fit(x_train,y_train)\n",
    "predicted = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(solver='lbfgs').fit(x_train_res,y_train_res)\n",
    "logistic_predict = logistic_model.predict(x_test)\n",
    "logistic_conusion_matrix = confusion_matrix(y_test,logistic_predict)\n",
    "logistic_conusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "# For Classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, min_samples_split=2, min_samples_leaf=1)\n",
    "model = tree.fit(X_train,y_train)\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "# For Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "# n_estimators is the number of trees to be used in the forest, by default is 10.\n",
    "\n",
    "# For Classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators = 100, criterion='gini')\n",
    "rf_model = rf_model.fit(x_train_res, y_train_res)\n",
    "rf_model_predict = rf_model.predict(x_test)\n",
    "rf_conusion_matrix = confusion_matrix(y_test,rf_model_predict)\n",
    "rf_conusion_matrix\n",
    "\n",
    "# For Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN - K nearest Neighbour\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model = knn_model.fit(x_train_res,y_train_res)\n",
    "knn_predict = knn_model.predict(x_test)\n",
    "knn_conusion_matrix = confusion_matrix(y_test,knn_predict)\n",
    "knn_conusion_matrix\n",
    "\n",
    "# Choosing a K Value with Elbow method\n",
    "error_rate = []\n",
    "k_list = [3,7,9,11,13,15,17,19,21,23,25,27,29]\n",
    "for i in k_list:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train_res,y_train_res)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "    \n",
    "# Plotting Residuals by Elbow method\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(k_list,error_rate,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - Support Vector Machine\n",
    "# For Classification\n",
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='rbf')\n",
    "model = model.fit(X_train,y_train)\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "# For Regression\n",
    "\n",
    "from sklearn import svmr\n",
    "model = svm.SVC(kernel='rbf')\n",
    "model = model.fit(X_train,y_train)\n",
    "predicted = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADABOOST - Adaptive Boosting\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "adaboost_classifier = AdaBoostClassifier( DecisionTreeClassifier(max_depth=3), n_estimators=400, learning_rate=.0001)\n",
    "adaboost_model = adaboost_classifier.fit(x_train_res,y_train_res)\n",
    "adaboost_predict = adaboost_model.predict(x_test)\n",
    "adaboost__conusion_matrix = confusion_matrix(y_test,adaboost_predict)\n",
    "adaboost__conusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG BOOST - Extream Gradient Boosting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Model_Evaluation'></a>\n",
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report All Results into Dataframe - Creating Method Where Evaluation Parameters will generate from Concusion Matrix\n",
    "report_comments, report_Accuracy, report_Precision, report_Recall , report_F1_Score= [],[],[],[],[]\n",
    "\n",
    "def report_generate(conf_mat,comment):\n",
    "\n",
    "    # Append Comment into List\n",
    "    report_comments.append(comment)\n",
    "\n",
    "    # Calculating Accuracy and Append into List\n",
    "    accuracy = (conf_mat[1][1] + conf_mat[0][0])/ (conf_mat[1][1] + conf_mat[0][0] + conf_mat[0][1] + conf_mat[1][0])\n",
    "    report_Accuracy.append(accuracy)\n",
    "    \n",
    "    # Calculating Precision and Append into List\n",
    "    precisoin = (conf_mat[0][0])/(conf_mat[0][1] + conf_mat[0][0])\n",
    "    report_Precision.append(precisoin)\n",
    "    \n",
    "    # Calculating Recall and Append into List\n",
    "    recall = (conf_mat[0][0])/(conf_mat[1][0] + conf_mat[0][0])\n",
    "    report_Recall.append(recall)\n",
    "    \n",
    "    # Calculating F1-Score and Append into List\n",
    "    f1scrore = 2 * precisoin * recall / (precisoin + recall) \n",
    "    report_F1_Score.append(f1scrore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report All Results into Dataframe\n",
    "def show_report():\n",
    "    report_data = {'Comment': report_comments,\n",
    "               'Accuracy': report_Accuracy,\n",
    "               'Precision': report_Precision,\n",
    "               'Recall': report_Recall ,\n",
    "               'F1 Score': report_F1_Score\n",
    "              }\n",
    "    df_results = pd.DataFrame.from_dict(report_data)\n",
    "    return(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass all Generated Confusion Matrix for generate report\n",
    "report_generate(logistic_conusion_matrix, comment='After SMOTE Logistic Regression')\n",
    "report_generate(knn_conusion_matrix, comment='After SMOTE KNN for K = 3')\n",
    "report_generate(rf_conusion_matrix, comment='After SMOTE Random Forest')\n",
    "\n",
    "show_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Conclusion'></a>\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "With references of the above models and model evaluations we can say that Random Forest model is giving the best solution for the given problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
